# -*- coding: utf-8 -*-
"""FA.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1wdXzUYM1iMk-JfF8GNe5eQpO93VjhJwJ
"""

import yfinance as yf
import pandas as pd

def fetch_prices(tickers, start="2015-01-01", end="2024-12-31"):
    """
    Fetches adjusted close prices for given tickers using Yahoo Finance.
    Returns a DataFrame with tickers as columns and dates as index.
    """
    data = yf.download(tickers, start=start, end=end, auto_adjust=False)

    if len(tickers) > 1:
        adj_close = pd.DataFrame({ticker: data[ticker]["Adj Close"] for ticker in tickers})
    else:
        adj_close = data["Adj Close"].to_frame(tickers[0])

    adj_close.dropna(inplace=True)
    return adj_close

"""#  Load S&P 500 Tickers and Fetch Full Dataset"""

import pandas as pd
import yfinance as yf

# You can download a list of S&P 500 tickers from Wikipedia (or any other list of tickers)
import requests

def get_sp500_tickers():
    url = 'https://en.wikipedia.org/wiki/List_of_S%26P_500_companies'
    tables = pd.read_html(url)
    tickers = tables[0]['Symbol'].tolist()
    return tickers

def fetch_all_data(tickers, start, end):
    # Download all data for the tickers
    data = yf.download(tickers, start=start, end=end, group_by='ticker', auto_adjust=False)

    # If single ticker, expand the structure to match the multi-ticker format
    if len(tickers) == 1:
        ticker = tickers[0]
        data.columns = pd.MultiIndex.from_product([[ticker], data.columns])

    return data

# Fetch the list of S&P 500 tickers
tickers = get_sp500_tickers()

# Specify the date range
start_date = "2015-01-01"
end_date = "2024-12-31"

# Fetch data for all tickers
prices_all = fetch_all_data(tickers, start_date, end_date)

# Example: Display first 20 rows of the data
print(prices_all.head())

"""# Extract close price

"""

# Extract only the Adjusted Close prices
adj_close = pd.DataFrame({ticker: prices_all[ticker]['Adj Close'] for ticker in tickers if ticker in prices_all.columns.levels[0]})

# Drop tickers with all NaNs
adj_close.dropna(axis=1, how='all', inplace=True)

# Preview
print(f"âœ… Adjusted Close shape: {adj_close.shape}")
adj_close.head()

"""# Calculate daily returns"""

# Calculate daily percentage returns
returns = adj_close.pct_change().dropna()

# Preview result
print(f"âœ… Returns shape: {returns.shape}")
returns.head()

"""# construct equal weight portfolio"""

import numpy as np
# Recalculate returns as before
returns = adj_close.pct_change()

# For each day, only use available tickers (not NaN)
def equal_weight_portfolio(returns_df):
    port_ret = []
    for idx, row in returns_df.iterrows():
        vals = row.dropna()
        if len(vals) > 0:
            weight = 1 / len(vals)
            port_ret.append((vals * weight).sum())
        else:
            port_ret.append(np.nan)
    return pd.Series(port_ret, index=returns_df.index, name="Portfolio_Return")

weighted_returns = equal_weight_portfolio(returns)
weighted_returns = weighted_returns.dropna()

print(f"ðŸ“ˆ Rolling equal-weight portfolio shape: {weighted_returns.shape}")
weighted_returns.head()

"""# Downloading and aligning market returns from S&P500"""

# Download S&P 500 index (^GSPC)
sp500 = yf.download("^GSPC", start="2015-01-01", end="2024-12-31", auto_adjust=True)["Close"]
sp500_returns = sp500.pct_change().dropna()
sp500_returns.name = "Market_Return"

# Align portfolio and market returns
aligned = pd.concat([weighted_returns, sp500_returns], axis=1).dropna()

# Preview
print(f"âœ… Aligned shape: {aligned.shape}")
aligned.head()

# Download S&P 500 index (^GSPC)
sp500 = yf.download("^GSPC", start="2015-01-01", end="2024-12-31", auto_adjust=True)["Close"]
sp500.name = "S&P500"

# Calculate S&P500 daily returns and rename column
sp500_returns = sp500.pct_change().dropna()
sp500_returns.name = "Market_Return"

# Align with portfolio
aligned = pd.concat([weighted_returns, sp500_returns], axis=1).dropna()
aligned.columns = ["Portfolio_Return", "Market_Return"]  # enforce naming

# Confirm it's good
print(aligned.head(30))

"""# Regression beta CAPM model"""

import statsmodels.api as sm

X = sm.add_constant(aligned["Market_Return"])
y = aligned["Portfolio_Return"]

model = sm.OLS(y, X).fit()
beta = model.params["Market_Return"]

print(f"ðŸ“Œ Portfolio Beta: {beta:.4f}")

"""# calculating sharpe ratio"""

# Load risk-free rate from Yahoo Finance
risk_free = yf.download("^IRX", start="2015-01-01", end="2024-12-31")["Close"] / 100
risk_free.name = "Risk_Free_Rate"

# Align dates
rf_aligned = pd.concat([weighted_returns, risk_free], axis=1).dropna()
rf_aligned.columns = ["Portfolio_Return", "Risk_Free_Rate"]

# Convert annualized % to daily decimal return
rf_aligned["Risk_Free_Rate"] = (1 + rf_aligned["Risk_Free_Rate"]) ** (1/252) - 1

# Excess return
excess_return = rf_aligned["Portfolio_Return"] - rf_aligned["Risk_Free_Rate"]

# Sharpe Ratio (annualized)
sharpe_ratio = (excess_return.mean() / excess_return.std()) * (252 ** 0.5)
print(f"ðŸ“Œ Annualized Sharpe Ratio: {sharpe_ratio:.4f}")

"""# calculate annual volatility"""

# Annualized volatility (standard deviation of daily returns Ã— sqrt(252))
port_volatility = weighted_returns.std() * (252 ** 0.5)

# Interpret risk level
if port_volatility < 0.10:
    risk_level = "ðŸŸ¢ Low Risk â€“ Stable portfolio with limited fluctuations."
elif port_volatility < 0.20:
    risk_level = "ðŸŸ¡ Moderate Risk â€“ Balanced risk and return profile."
else:
    risk_level = "ðŸ”´ High Risk â€“ Expect significant value swings."

print(f"ðŸ“ˆ Annualized Volatility: {port_volatility:.2%}")
print(f"ðŸ“Œ Risk Interpretation: {risk_level}")

"""# Calculate value at risk VaR"""

from scipy.stats import norm

confidence_level = 0.95
z_score = norm.ppf(1 - confidence_level)  # â‰ˆ -1.645

# Calculate daily VaR as a % (normal assumption)
VaR_95 = -z_score * weighted_returns.std()

# Convert to dollar loss on a $10,000 portfolio
portfolio_value = 10000
VaR_dollar = VaR_95 * portfolio_value

# Risk message
if VaR_95 < 0.01:
    risk_comment = "ðŸŸ¢ Low loss potential â€“ relatively stable portfolio."
elif VaR_95 < 0.03:
    risk_comment = "ðŸŸ¡ Moderate loss potential â€“ monitor during volatility."
else:
    risk_comment = "ðŸ”´ High loss risk â€“ portfolio may see significant drops."

# Output
print(f"âš ï¸  Value at Risk (95% confidence): {VaR_95:.2%}")
print(f"ðŸ’µ Estimated Max Daily Loss: ${VaR_dollar:,.2f}")
print(f"ðŸ“Œ Interpretation: {risk_comment}")

yf.download("AAPL", period="1d", interval="1m")

!pip install arch

"""# Fitting GARCH model and forecasting volatility"""

from arch import arch_model
import matplotlib.pyplot as plt

# Clean input for GARCH: convert returns to percent and drop missing
garch_returns = weighted_returns * 100
garch_returns = garch_returns.dropna()

# Fit GARCH(1,1)
garch_model = arch_model(garch_returns, vol='Garch', p=1, q=1, rescale=False)
garch_fit = garch_model.fit(disp="off")

# Forecast next 30 days of volatility
garch_forecast = garch_fit.forecast(horizon=30)
volatility_forecast = np.sqrt(garch_forecast.variance.values[-1, :])

# Plot forecast
plt.figure(figsize=(10, 5))
plt.plot(volatility_forecast, marker='o', linestyle='-', color='orange')
plt.title("Forecasted 30-Day Volatility (GARCH)", fontsize=14)
plt.xlabel("Day Ahead")
plt.ylabel("Volatility (%)")
plt.grid(True)
plt.tight_layout()
plt.show()

"""# Real time price fetch function for 3 stocks

"""

def get_live_price(ticker):
    stock = yf.Ticker(ticker)
    todays_data = stock.history(period='1d', interval='1m')

    if not todays_data.empty:
        latest_price = todays_data['Close'].iloc[-1]
        print(f"ðŸ“ˆ {ticker}: ${latest_price:.2f}")
        return latest_price
    else:
        print(f"âŒ No real-time data for {ticker}")
        return None

# Example: Fetch prices for multiple tickers
portfolio_tickers = ["AAPL", "MSFT", "GOOGL"]  # or use returns.columns.tolist() for all 346
live_prices = {}

for ticker in portfolio_tickers:
    price = get_live_price(ticker)
    if price is not None:
        live_prices[ticker] = price

print("\nâœ… Live prices fetched:")
print(live_prices)

"""# Calculate today's portfolio return"""

# Ensure you're only using adjusted close values
adj_close_only = prices_all.xs('Adj Close', axis=1, level=1)

# Now extract just the portfolio tickers
portfolio_tickers = ['AAPL', 'MSFT', 'GOOGL']
initial = adj_close_only[portfolio_tickers].iloc[-2]
latest = adj_close_only[portfolio_tickers].iloc[-1]
# Equal weights
weights = [1 / len(portfolio_tickers)] * len(portfolio_tickers)

# Calculate today's return
today_return = ((latest - initial) / initial).dot(weights)

# Assume $10,000 invested
portfolio_value = 10000
gain_loss = today_return * portfolio_value

# Output
print(f"ðŸ“ˆ Today's Portfolio Return: {today_return:.2%}")
print(f"ðŸ’µ Gain/Loss on $10,000: ${gain_loss:.2f}")



"""# Monte Carlo Simulation

Monte Carlo Simulation pipeline to simulate the possible future value paths of your portfolio, estimate risk
"""

import numpy as np
import matplotlib.pyplot as plt

# Inputs (use your existing values)
portfolio_value = 10000  # or set via user input
num_days = 30
num_simulations = 1000

# Daily return stats from portfolio history
mu = portfolio_returns.mean()
sigma = portfolio_returns.std()

# Create matrix to hold simulations
simulated_paths = np.zeros((num_days, num_simulations))

# Simulate paths
for i in range(num_simulations):
    # Generate random daily returns for 'num_days'
    daily_returns = np.random.normal(loc=mu, scale=sigma, size=num_days)
    # Convert to price path starting at 1
    price_path = np.cumprod(1 + daily_returns)
    # Scale by portfolio value
    simulated_paths[:, i] = portfolio_value * price_path

plt.figure(figsize=(12, 6))
plt.plot(simulated_paths, color="lightblue", linewidth=0.8, alpha=0.5)
plt.title(f"Monte Carlo Simulation ({num_simulations} runs, {num_days} days)")
plt.xlabel("Day")
plt.ylabel("Portfolio Value ($)")
plt.grid(True)
plt.tight_layout()
plt.show()

# Distribution of end-of-period values
final_values = simulated_paths[-1, :]

# Value at Risk (95% confidence)
var_95 = portfolio_value - np.percentile(final_values, 5)

# Mean ending value
mean_final = np.mean(final_values)

# Worst-case and best-case
min_final = np.min(final_values)
max_final = np.max(final_values)

print(f"ðŸ“‰ Mean expected portfolio value after {num_days} days: ${mean_final:,.2f}")
print(f"âš ï¸  Value at Risk (95% confidence): You might lose up to ${var_95:,.2f}")
print(f"ðŸ”» Worst-case (simulated): ${min_final:,.2f}")
print(f"ðŸ”º Best-case (simulated): ${max_final:,.2f}")



"""# K-Means Clustering for user portfolio"""

import pandas as pd
import numpy as np
from sklearn.cluster import KMeans
import matplotlib.pyplot as plt
import seaborn as sns

# âœ… Your portfolio tickers from returns DataFrame
portfolio_stocks = returns.columns.tolist()

# Calculate features: mean return and volatility (std)
features = pd.DataFrame({
    "Mean_Return": returns.mean(),
    "Volatility": returns.std()
})

n_assets = len(portfolio_stocks)
n_clusters = min(3, n_assets)  # At most 3 clusters for readability

kmeans = KMeans(n_clusters=n_clusters, random_state=42)
features["Cluster"] = kmeans.fit_predict(features[["Mean_Return", "Volatility"]])

plt.figure(figsize=(8, 6))
sns.scatterplot(
    data=features,
    x="Volatility", y="Mean_Return",
    hue="Cluster", palette="tab10", s=100
)
for ticker, row in features.iterrows():
    plt.text(row["Volatility"], row["Mean_Return"], ticker, fontsize=9, ha="left")

plt.title("K-Means Clustering of Your Portfolio Assets")
plt.xlabel("Volatility (Risk)")
plt.ylabel("Mean Return")
plt.grid(True)
plt.tight_layout()
plt.show()

print("ðŸ§  Interpretation:")

cluster_counts = features["Cluster"].value_counts()
dominant_cluster = cluster_counts.idxmax()
dominant_pct = cluster_counts.max() / n_assets

cluster_means = features.groupby("Cluster").mean()

for i in range(n_clusters):
    mean_ret = cluster_means.loc[i, "Mean_Return"]
    vol = cluster_means.loc[i, "Volatility"]
    print(f"\nðŸ“Š Cluster {i}:")
    print(f"  - Avg Return: {mean_ret:.4f}")
    print(f"  - Avg Volatility: {vol:.4f}")
    if mean_ret > 0 and vol > 0.03:
        print("  ðŸ”º High-risk, high-return assets.")
    elif mean_ret > 0 and vol <= 0.03:
        print("  âœ… Stable growth assets.")
    else:
        print("  âš ï¸ Low or negative return assets.")

# Diversification warning
if dominant_pct > 0.6:
    print(f"\nâš ï¸ Over 60% of your portfolio is in Cluster {dominant_cluster}. Consider diversifying.")
else:
    print("\nâœ… Your portfolio is well distributed across different risk-return profiles.")

# Calculate drawdowns and recovery per stock
drawdown_data = []

for ticker in returns.columns:
    ret = returns[ticker]
    cum_ret = (1 + ret).cumprod()

    running_max = cum_ret.cummax()
    drawdown = cum_ret / running_max - 1

    # Max drawdown value
    max_dd = drawdown.min()

    # Recovery time = how many days to get back to previous high
    recovery_time = 0
    peak_idx = drawdown.idxmin()
    post_peak = cum_ret.loc[peak_idx:]

    for i, val in enumerate(post_peak):
        if val >= running_max.loc[peak_idx]:
            recovery_time = i
            break
    else:
        recovery_time = np.nan  # Never recovered during observed period

    drawdown_data.append({
        "Ticker": ticker,
        "Max_Drawdown": max_dd,
        "Recovery_Days": recovery_time
    })

drawdown_df = pd.DataFrame(drawdown_data)

# Add cluster info from K-Means features
drawdown_df["Cluster"] = drawdown_df["Ticker"].map(features["Cluster"])

cluster_summary = drawdown_df.groupby("Cluster").agg({
    "Max_Drawdown": "mean",
    "Recovery_Days": "mean"
}).round(2)

print("ðŸ“‰ Historical Risk Behavior by Cluster:\n")
print(cluster_summary)